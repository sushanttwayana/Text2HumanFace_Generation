{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceType": "datasetVersion",
          "sourceId": 8323379,
          "datasetId": 4944262,
          "databundleVersionId": 8454756
        },
        {
          "sourceType": "datasetVersion",
          "sourceId": 37705,
          "datasetId": 29561,
          "databundleVersionId": 39327
        },
        {
          "sourceType": "datasetVersion",
          "sourceId": 8695562,
          "datasetId": 5204052,
          "databundleVersionId": 8847993
        },
        {
          "sourceType": "datasetVersion",
          "sourceId": 8713758,
          "datasetId": 5227713,
          "databundleVersionId": 8867073
        }
      ],
      "dockerImageVersionId": 30698,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Celeba_Dataset_Generation",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sushanttwayana/Text2HumanFace_Generation/blob/main/Celeba_Dataset_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'celeba-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F29561%2F37705%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240617%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240617T181210Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D572efabecf4823a42cb664573935c6fabe855cf5a1841f5df47352880eb571146c1d9931bf69c5b67335f2e6dfdcc028b579a526e2a006dfa718842eef147c431d99c0d0a5f45be72821b00fc32e8aba52f00033169ddf7bebf57d46d9fa4eee8aef061756bcd52bbffcda65452ae74c909d399dc1719b5becd32b212a1f8174f8967a022583e3de9841f3b48710a1c4af8bed6058e8c796869ad79fd78d39fcfe70acfa865359a343f5978e9f2eda82327d89e1a05c86bc6049597a89a1f9a5b7eb5f6d60b1bed11b1893a99aaf2fa2daee6010281a76b3419432259afda601544e5738105369641e118af23a156d0fa7fc1da97c084ec5e3e174ed7101f269,celeba-text:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4944262%2F8323379%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240617%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240617T181210Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D7745a3f9826cb33a654bb18c754e8ded5bdea08f5620866b7d1fd8741d994dd587f7eefa45dabb8d0fb367d41c59f520b024cfb199511f52f6d2c7b3709c63f70b127282ce48484fd6a9aabd411d5f8af5b4610a2485d105d88264686fdb92af7559bc25c91cd66f7a71804b89896eb11ece2a0d61427203487e9c03db7e7116554f545df16555c704105a9312dcdb387b93a2b0d4ac471dd3c9b4bf36bef6b40b3c4e8178f1c8317ba90cc9541f0540d64f5691f9ffe127825ec3c9ba998dce224c695b5d51a33471e4a675879fd462b8ce4219983043b6b9ecb39c2008db1b8ea8fee38b5a51d394d4075abe594ceb403781aca6ee928abea25e16d9d2a46e,emotionaldataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F5204052%2F8695562%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240617%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240617T181210Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D3eb2972e4cefd7bc1924f074445d8755490b10448ded9ceb85554b8bcde7393c2168388f139c68e4fe84a67d3631c6a8f00321d173348f96bf92b78f5a77cdc4c92e2c8109bbb9d00c411304568362072550028ce7ba8f3d5c95f7e7c21fe583da296704c072074fd38c587b0a904d81c48062428e2e66f3e4bbc6871aff9b844bcf75e3bb270d9352fefbc2455ab81c914d4d3d2a296ae6f220f83e6b5599df695203f98d7c0c185d18f184f034398d6c9f5189195aab0daa4a51528831b6c8a8ccda56e4be9ae2ea7cba5454ddb0d902056331e2a9b2ccf143fdc5e6958dcdcd65eb62f3786159f45627bf4fbfc5544b41dcc4d1e543a8e2532206ea5947c0,final-celeba-12000:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F5227713%2F8713758%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240617%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240617T181211Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D690b5c560e1972ca1dc8d0e673c8747be0989b1ffaa078fa2e75bd421fef7b0ef36c5552f60a8517decf4acbb6d7cc563b660acc629b03788d8acc5237aa7bebbcd82b56783dea88dc2595b4b769e3c80c7907d527694b77a165c84a1470c096c0753416c99ea3b46e863015d282675d7c1bc93dd88ba6a4464e30e145b6fc1bf066594ba0963a76683a3abb4121423e5d86c5194a98ae4b6586d970070fc3e0aa357d89b53dad66b282171698f746f062df605d66abe5f06fef3d81c21bdd87cea17989ff132b2dd74dacefa28cc2cf093412751b116396a1793be483a23ce0e9b8ab71b822f9b12cc05688915680cf9c68f0eb757c7cfad326eb387d966258'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "uZCMZVmNZk3J"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Load the JSON data from the file\n",
        "with open('/kaggle/working/final_sorted_csv_120000..json', 'r') as json_file:\n",
        "    data = json.load(json_file)\n",
        "\n",
        "# Define the desired text format\n",
        "text = ''\n",
        "\n",
        "# Process each item in the list\n",
        "for item in data:\n",
        "    text += f\"{item}\\n\"  # Assuming each item is a string representation\n",
        "\n",
        "# Write the text to a new file\n",
        "with open('/kaggle/working/final_celeba_120000.txt', 'w') as text_file:\n",
        "    text_file.write(text)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-17T17:24:30.358826Z",
          "iopub.execute_input": "2024-06-17T17:24:30.359201Z",
          "iopub.status.idle": "2024-06-17T17:24:33.5554Z",
          "shell.execute_reply.started": "2024-06-17T17:24:30.359173Z",
          "shell.execute_reply": "2024-06-17T17:24:33.554411Z"
        },
        "trusted": true,
        "id": "2NDTZoONZk3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import json\n",
        "\n",
        "def csv_to_json(csv_file_path, json_file_path):\n",
        "    data = []\n",
        "    with open(csv_file_path, 'r') as csv_file:\n",
        "        csv_reader = csv.DictReader(csv_file)\n",
        "        for row in csv_reader:\n",
        "            data.append(row)\n",
        "\n",
        "    with open(json_file_path, 'w') as json_file:\n",
        "        json.dump(data, json_file, indent=4)\n",
        "\n",
        "# Example usage\n",
        "csv_to_json('/kaggle/input/final-celeba-12000/final_sorted_csv_120000.csv', '/kaggle/working/final_sorted_csv_120000..json')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-17T17:23:22.594698Z",
          "iopub.execute_input": "2024-06-17T17:23:22.595052Z",
          "iopub.status.idle": "2024-06-17T17:23:31.541809Z",
          "shell.execute_reply.started": "2024-06-17T17:23:22.595024Z",
          "shell.execute_reply": "2024-06-17T17:23:31.540751Z"
        },
        "trusted": true,
        "id": "RD31-Z20Zk3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "\n",
        "def generate_captions_from_attributes(attributes_file, output_file, exclude_attributes):\n",
        "    captions = []\n",
        "\n",
        "    # Read the attributes from the file\n",
        "    with open(attributes_file, 'r') as file:\n",
        "        reader = csv.DictReader(file)\n",
        "        for row in reader:\n",
        "            image_id = row['image_id']\n",
        "\n",
        "            # Convert attributes to textual description\n",
        "            description = []\n",
        "            gender = \"male\" if row['Male'] == '1' else \"female\"\n",
        "            description.append(f\"This person is {gender}\")\n",
        "\n",
        "            pronoun = \"He\" if gender == \"male\" else \"She\"\n",
        "            possessive_pronoun = \"his\" if gender == \"male\" else \"her\"\n",
        "\n",
        "            # Include attributes in the description\n",
        "            for attribute, value in row.items():\n",
        "                if attribute == 'image_id' or attribute == 'Male':\n",
        "                    continue\n",
        "                if exclude_attributes and attribute in exclude_attributes:\n",
        "                    continue\n",
        "\n",
        "                if value == '1':\n",
        "                    if attribute == '5_o_Clock_Shadow':\n",
        "                        description.append(f\"{pronoun} has dense beard.\")\n",
        "                    elif attribute == 'Arched_Eyebrows':\n",
        "                        description.append(f\"{pronoun} has arched eyebrows.\")\n",
        "                    elif attribute == 'Attractive':\n",
        "                        description.append(f\"{pronoun} is attractive.\")\n",
        "                    elif attribute == 'Bags_Under_Eyes':\n",
        "                        description.append(f\"{pronoun} has bags under {possessive_pronoun} eyes.\")\n",
        "                    elif attribute == 'Bald':\n",
        "                        description.append(f\"{pronoun} is bald.\")\n",
        "                    elif attribute == 'Bangs':\n",
        "                        description.append(f\"{pronoun} has bangs.\")\n",
        "                    elif attribute == 'Big_Lips':\n",
        "                        description.append(f\"{pronoun} has big lips.\")\n",
        "                    elif attribute == 'Big_Nose':\n",
        "                        description.append(f\"{pronoun} has a big nose.\")\n",
        "                    elif attribute == 'Black_Hair':\n",
        "                        description.append(f\"{pronoun} has black hair.\")\n",
        "                    elif attribute == 'Blond_Hair':\n",
        "                        description.append(f\"{pronoun} has blonde hair.\")\n",
        "                    elif attribute == 'Brown_Hair':\n",
        "                        description.append(f\"{pronoun} has brown hair.\")\n",
        "                    elif attribute == 'Bushy_Eyebrows':\n",
        "                        description.append(f\"{pronoun} has bushy eyebrows.\")\n",
        "                    elif attribute == 'Chubby':\n",
        "                        description.append(f\"{pronoun} is chubby.\")\n",
        "                    elif attribute == 'Double_Chin':\n",
        "                        description.append(f\"{pronoun} has a double chin.\")\n",
        "                    elif attribute == 'Eyeglasses':\n",
        "                        description.append(f\"{pronoun} is wearing eyeglasses.\")\n",
        "                    elif attribute == 'Goatee':\n",
        "                        description.append(f\"{pronoun} has a goatee beard.\")\n",
        "                    elif attribute == 'Gray_Hair':\n",
        "                        description.append(f\"{pronoun} has gray hair.\")\n",
        "                    elif attribute == 'Heavy_Makeup':\n",
        "                        description.append(f\"{pronoun} is wearing heavy makeup.\")\n",
        "                    elif attribute == 'High_Cheekbones':\n",
        "                        description.append(f\"{pronoun} has high cheekbones.\")\n",
        "                    elif attribute == 'Mouth_Slightly_Open':\n",
        "                        description.append(f\"{pronoun} has {possessive_pronoun} mouth slightly open.\")\n",
        "                    elif attribute == 'Mustache':\n",
        "                        description.append(f\"{pronoun} has a mustache.\")\n",
        "                    elif attribute == 'Narrow_Eyes':\n",
        "                        description.append(f\"{pronoun} has narrow eyes.\")\n",
        "                    elif attribute == 'Oval_Face':\n",
        "                        description.append(f\"{pronoun} has an oval face.\")\n",
        "                    elif attribute == 'Pale_Skin':\n",
        "                        description.append(f\"{pronoun} has pale skin.\")\n",
        "                    elif attribute == 'Pointy_Nose':\n",
        "                        description.append(f\"{pronoun} has a pointy nose.\")\n",
        "                    elif attribute == 'Receding_Hairline':\n",
        "                        description.append(f\"{pronoun} has a receding hairline.\")\n",
        "                    elif attribute == 'Rosy_Cheeks':\n",
        "                        description.append(f\"{pronoun} has rosy cheeks.\")\n",
        "                    elif attribute == 'Sideburns':\n",
        "                        description.append(f\"{pronoun} has sideburns.\")\n",
        "                    elif attribute == 'Smiling':\n",
        "                        description.append(f\"{pronoun} is smiling.\")\n",
        "                    elif attribute == 'Straight_Hair':\n",
        "                        description.append(f\"{pronoun} has straight hair.\")\n",
        "                    elif attribute == 'Wavy_Hair':\n",
        "                        description.append(f\"{pronoun} has wavy hair.\")\n",
        "                    elif attribute == 'Wearing_Earrings':\n",
        "                        description.append(f\"{pronoun} is wearing earrings.\")\n",
        "                    elif attribute == 'Wearing_Hat':\n",
        "                        description.append(f\"{pronoun} is wearing a hat.\")\n",
        "                    elif attribute == 'Wearing_Lipstick':\n",
        "                        description.append(f\"{pronoun} is wearing lipstick.\")\n",
        "                    elif attribute == 'Wearing_Necklace':\n",
        "                        description.append(f\"{pronoun} is wearing a necklace.\")\n",
        "                    elif attribute == 'Wearing_Necktie':\n",
        "                        description.append(f\"{pronoun} is wearing a necktie.\")\n",
        "                    elif attribute == 'Young':\n",
        "                        description.append(f\"{pronoun} is young.\")\n",
        "                    elif attribute == \"happy\":\n",
        "                        description.append(f\"{pronoun} is happy.\")\n",
        "                        description.append(f\"{pronoun} looks happy.\")\n",
        "                        description.append(f\"{pronoun} is joyful and delighted.\")\n",
        "                        description.append(f\"{pronoun} has a happy expression.\")\n",
        "                        description.append(f\"{pronoun} seems blissful.\")\n",
        "                        description.append(f\"{pronoun} is cheerful.\")\n",
        "                    elif attribute == \"sad\":\n",
        "                        description.append(f\"{pronoun} is sad.\")\n",
        "                        description.append(f\"{pronoun} looks sad.\")\n",
        "                        description.append(f\"{pronoun} looks unhappy and sad.\")\n",
        "                        description.append(f\"{pronoun} looks depressed.\")\n",
        "                        description.append(f\"{pronoun} is feeling down.\")\n",
        "                        description.append(f\"{pronoun} has a sad expression.\")\n",
        "                    elif attribute == \"neutral\":\n",
        "                        description.append(f\"{pronoun} is neutral.\")\n",
        "                        description.append(f\"{pronoun} stays calm and neutral.\")\n",
        "                        description.append(f\"{pronoun} stays open-minded and is fair-minded.\")\n",
        "\n",
        "                elif value == '-1':\n",
        "                    if attribute == 'No_Beard':\n",
        "                        description.append(f\"{pronoun} has a beard.\")\n",
        "                    elif attribute == 'Young':\n",
        "                        description.append(f\"{pronoun} is old.\")\n",
        "                    elif attribute == 'Pale_Skin':\n",
        "                        description.append(f\"{pronoun} has brown skin.\")\n",
        "                    elif attribute == 'Chubby':\n",
        "                        description.append(f\"{pronoun} is slim.\")\n",
        "                    elif attribute == 'Bald':\n",
        "                        description.append(f\"{pronoun} has hair.\")\n",
        "                    elif attribute == 'Big_Lips':\n",
        "                        description.append(f\"{pronoun} has thin lips.\")\n",
        "                    elif attribute == 'Big_Nose':\n",
        "                        description.append(f\"{pronoun} has a small nose.\")\n",
        "                    elif attribute == 'Mustache':\n",
        "                        if row['Male'] == '1':\n",
        "                            description.append(f\"{pronoun} is clean-shaven and has no facial hairs.\")\n",
        "                        else :\n",
        "                            description.append(f\"{pronoun} has no facial hairs.\")\n",
        "                    elif attribute == 'Oval_Face':\n",
        "                        description.append(f\"{pronoun} has a round face.\")\n",
        "                    elif attribute == 'Straight_Hair':\n",
        "                        description.append(f\"{pronoun} has curly hair.\")\n",
        "                    elif attribute == 'Sideburns':\n",
        "                        description.append(f\"{pronoun} has bare cheeks. {pronoun} has no facial hair on the sides.\")\n",
        "                    elif attribute == 'Pointy_Nose':\n",
        "                        description.append(f\"{pronoun} has a rounded nose.\")\n",
        "                    elif attribute == 'High_Cheekbones':\n",
        "                        description.append(f\"{pronoun} has flat cheekbones.\")\n",
        "                    elif attribute == 'Heavy_Makeup':\n",
        "                        description.append(f\"{pronoun} is wearing no makeup. {pronoun} is wearing light makeup.\")\n",
        "                    elif attribute == 'Smiling':\n",
        "                        description.append(f\"{pronoun} is not smiling.\")\n",
        "                    elif attribute == 'Mouth_Slightly_Open':\n",
        "                        description.append(f\"{pronoun} has {possessive_pronoun} mouth closed.\")\n",
        "\n",
        "            captions.append((image_id, ' '.join(description)))\n",
        "\n",
        "    # Save captions to output file\n",
        "    if not os.path.exists(os.path.dirname(output_file)):\n",
        "        os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
        "\n",
        "    with open(output_file, 'w') as file:\n",
        "        file.write(\"image,caption\\n\")  # Write the header line\n",
        "        for image_id, description in captions:\n",
        "            file.write(f\"{image_id},{description}\\n\")\n",
        "\n",
        "# Example usage:\n",
        "attributes_file = '/kaggle/input/final-celeba-12000/final_sorted_csv_120000.csv'\n",
        "output_file = '/kaggle/working/descriptions/celeba_120000_captions.txt'\n",
        "exclude_attributes = ['Blurry']  # Example of attributes to exclude\n",
        "generate_captions_from_attributes(attributes_file, output_file, exclude_attributes)\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-06-17T17:46:20.363153Z",
          "iopub.execute_input": "2024-06-17T17:46:20.36352Z",
          "iopub.status.idle": "2024-06-17T17:46:25.686831Z",
          "shell.execute_reply.started": "2024-06-17T17:46:20.36349Z",
          "shell.execute_reply": "2024-06-17T17:46:25.685857Z"
        },
        "trusted": true,
        "id": "lW4VYLCRZk3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from keras.utils.np_utils import to_categorical\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import random\n",
        "# import sys\n",
        "# import warnings\n",
        "# warnings.filterwarnings('ignore')\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "# %matplotlib inline\n",
        "\n",
        "# import brewer2mpl\n",
        "\n",
        "\n",
        "# def emotion_count(y_train, classes):\n",
        "#     \"\"\"\n",
        "#     The function re-classify picture with disgust label into angry label\n",
        "#     \"\"\"\n",
        "#     emo_classcount = {}\n",
        "#     print ('Disgust classified as Angry')\n",
        "#     y_train.loc[y_train == 1] = 0\n",
        "#     classes.remove('Disgust')\n",
        "#     for new_num, _class in enumerate(classes):\n",
        "#         y_train.loc[(y_train == emotion[_class])] = new_num\n",
        "#         class_count = sum(y_train == (new_num))\n",
        "#         emo_classcount[_class] = (new_num, class_count)\n",
        "#     return y_train.values, emo_classcount\n",
        "\n",
        "# def load_data(sample_split=0.3, usage='Training',classes=['Angry','Happy'], filepath='../input/fer20131.csv'):\n",
        "#     \"\"\"\n",
        "#     The function load provided CSV dataset and further reshape, rescale the data for feeding\n",
        "#     \"\"\"\n",
        "#     df = pd.read_csv(filepath)\n",
        "#     df = df[df.Usage == usage]\n",
        "#     frames = []\n",
        "#     classes.append('Disgust')\n",
        "#     for _class in classes:\n",
        "#         class_df = df[df['emotion'] == emotion[_class]]\n",
        "#         frames.append(class_df)\n",
        "#     data = pd.concat(frames, axis=0)\n",
        "#     rows = random.sample(list(data.index), int(len(data)*sample_split))\n",
        "#     data = data.loc[rows]\n",
        "#     x = list(data[\"pixels\"])\n",
        "#     X = []\n",
        "#     for i in range(len(x)):\n",
        "#         each_pixel = [int(num) for num in x[i].split()]\n",
        "#         X.append(each_pixel)\n",
        "#     ## reshape into 48*48*1 and rescale\n",
        "#     X = np.array(X)\n",
        "#     X = X.reshape(X.shape[0], 48, 48,1)\n",
        "#     X = X.astype(\"float32\")\n",
        "#     X /= 255\n",
        "\n",
        "#     y_train, new_dict = emotion_count(data.emotion, classes)\n",
        "#     y_train = to_categorical(y_train)\n",
        "#     return X, y_train"
      ],
      "metadata": {
        "id": "rfMoeWXqZk3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Emotional Dataset Generation"
      ],
      "metadata": {
        "id": "MC9ftPQ9Zk3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-14T03:47:21.175704Z",
          "iopub.execute_input": "2024-06-14T03:47:21.176075Z",
          "iopub.status.idle": "2024-06-14T03:47:37.859902Z",
          "shell.execute_reply.started": "2024-06-14T03:47:21.176046Z",
          "shell.execute_reply": "2024-06-14T03:47:37.858315Z"
        },
        "trusted": true,
        "id": "42f85EgzZk3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path ='/kaggle/input/your-dataset/your_model.h5'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-14T03:48:07.75297Z",
          "iopub.execute_input": "2024-06-14T03:48:07.760206Z",
          "iopub.status.idle": "2024-06-14T03:48:07.770225Z",
          "shell.execute_reply.started": "2024-06-14T03:48:07.76015Z",
          "shell.execute_reply": "2024-06-14T03:48:07.766445Z"
        },
        "trusted": true,
        "id": "r7sCd8VfZk3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the model\n",
        "loaded_model = load_model('/kaggle/input/emotionaldataset/model.h5')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-14T03:48:10.783389Z",
          "iopub.execute_input": "2024-06-14T03:48:10.784349Z",
          "iopub.status.idle": "2024-06-14T03:48:25.698403Z",
          "shell.execute_reply.started": "2024-06-14T03:48:10.784293Z",
          "shell.execute_reply": "2024-06-14T03:48:25.697203Z"
        },
        "trusted": true,
        "id": "iUW1IsfmZk3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-14T03:48:38.388853Z",
          "iopub.execute_input": "2024-06-14T03:48:38.389802Z",
          "iopub.status.idle": "2024-06-14T03:48:38.452856Z",
          "shell.execute_reply.started": "2024-06-14T03:48:38.389764Z",
          "shell.execute_reply": "2024-06-14T03:48:38.451793Z"
        },
        "trusted": true,
        "id": "LKVSs7g5Zk3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "# Load the image\n",
        "image_path = '/kaggle/input/celeba-dataset/img_align_celeba/img_align_celeba/000050.jpg'  # Replace with your image file path\n",
        "image = Image.open(image_path)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-13T17:10:01.624541Z",
          "iopub.execute_input": "2024-06-13T17:10:01.624927Z",
          "iopub.status.idle": "2024-06-13T17:10:01.639135Z",
          "shell.execute_reply.started": "2024-06-13T17:10:01.624898Z",
          "shell.execute_reply": "2024-06-13T17:10:01.637815Z"
        },
        "trusted": true,
        "id": "YGJqrWW4Zk3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resize the image to 48x48\n",
        "resized_image = image.resize((48, 48))\n",
        "\n",
        "# Convert the resized image to numpy array (optional)\n",
        "import numpy as np\n",
        "resized_image_array = np.array(resized_image)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-13T17:10:04.154685Z",
          "iopub.execute_input": "2024-06-13T17:10:04.155133Z",
          "iopub.status.idle": "2024-06-13T17:10:04.163764Z",
          "shell.execute_reply.started": "2024-06-13T17:10:04.155098Z",
          "shell.execute_reply": "2024-06-13T17:10:04.161716Z"
        },
        "trusted": true,
        "id": "u5Cr18ryZk3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resized_image_gray = resized_image.convert('L')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-13T17:10:06.789069Z",
          "iopub.execute_input": "2024-06-13T17:10:06.789521Z",
          "iopub.status.idle": "2024-06-13T17:10:06.795228Z",
          "shell.execute_reply.started": "2024-06-13T17:10:06.789486Z",
          "shell.execute_reply": "2024-06-13T17:10:06.79385Z"
        },
        "trusted": true,
        "id": "5f6lUPBZZk3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Display the grayscale image using matplotlib\n",
        "plt.imshow(resized_image_gray, cmap='gray')\n",
        "plt.axis('off')  # Hide axes for better visualization\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-13T17:10:09.525237Z",
          "iopub.execute_input": "2024-06-13T17:10:09.525683Z",
          "iopub.status.idle": "2024-06-13T17:10:09.620142Z",
          "shell.execute_reply.started": "2024-06-13T17:10:09.52565Z",
          "shell.execute_reply": "2024-06-13T17:10:09.618579Z"
        },
        "trusted": true,
        "id": "lMYAC6wPZk3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the resized image to a format suitable for model input\n",
        "import tensorflow as tf\n",
        "resized_image_array = np.expand_dims(resized_image_gray, axis=0)  # Add batch dimension\n",
        "resized_image_array = np.expand_dims(resized_image_array, axis=-1)  # Add channels dimension (for grayscale)\n",
        "resized_image_array = resized_image_array.astype('float32') / 255.0  # Normalize pixel values\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-13T17:10:13.492688Z",
          "iopub.execute_input": "2024-06-13T17:10:13.493133Z",
          "iopub.status.idle": "2024-06-13T17:10:13.500019Z",
          "shell.execute_reply.started": "2024-06-13T17:10:13.493101Z",
          "shell.execute_reply": "2024-06-13T17:10:13.498773Z"
        },
        "trusted": true,
        "id": "_ENSZmjhZk3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction and true labels\n",
        "y_prob = loaded_model.predict(resized_image_array, batch_size=1, verbose=0)\n",
        "y_pred = [np.argmax(prob) for prob in y_prob]\n",
        "\n",
        "print(y_prob)\n",
        "print(y_pred)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-13T17:10:16.408834Z",
          "iopub.execute_input": "2024-06-13T17:10:16.409268Z",
          "iopub.status.idle": "2024-06-13T17:10:16.508102Z",
          "shell.execute_reply.started": "2024-06-13T17:10:16.40923Z",
          "shell.execute_reply": "2024-06-13T17:10:16.506913Z"
        },
        "trusted": true,
        "id": "dM4EWZufZk3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapper = {\n",
        "    0: \"happy\",\n",
        "    1: \"sad\",\n",
        "    2: \"neutral\",\n",
        "}\n",
        "\n",
        "emo     = [\"happy\", 'sad', 'neutral']\n",
        "\n",
        "# Using list comprehension to retrieve elements\n",
        "result = [emo[idx] for idx in y_pred]\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-13T17:10:19.835881Z",
          "iopub.execute_input": "2024-06-13T17:10:19.83627Z",
          "iopub.status.idle": "2024-06-13T17:10:19.843745Z",
          "shell.execute_reply.started": "2024-06-13T17:10:19.836242Z",
          "shell.execute_reply": "2024-06-13T17:10:19.842571Z"
        },
        "trusted": true,
        "id": "rBcJj4WzZk3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define the mapper and emotions\n",
        "mapper = {\n",
        "    0: \"happy\",\n",
        "    1: \"sad\",\n",
        "    2: \"neutral\",\n",
        "}\n",
        "\n",
        "emo = [\"happy\", \"sad\", \"neutral\"]\n",
        "\n",
        "# Load your pre-trained model\n",
        "# loaded_model = tf.keras.models.load_model('/kaggle/input/emotionaldataset/model.h5')\n",
        "\n",
        "# Define the directory containing tahe images\n",
        "image_directory = '/kaggle/input/celeba-dataset/img_align_celeba/img_align_celeba'\n",
        "\n",
        "# Prepare a list to store results\n",
        "results = []\n",
        "\n",
        "# Iterate over each image in the directory\n",
        "for image_name in os.listdir(image_directory):\n",
        "    if image_name.endswith('.jpg'):  # Add other image formats if needed\n",
        "        image_path = os.path.join(image_directory, image_name)\n",
        "\n",
        "        # Load and process the image\n",
        "        image = Image.open(image_path)\n",
        "        resized_image = image.resize((48, 48))\n",
        "        resized_image_gray = resized_image.convert('L')\n",
        "        resized_image_array = np.expand_dims(resized_image_gray, axis=0)  # Add batch dimension\n",
        "        resized_image_array = np.expand_dims(resized_image_array, axis=-1)  # Add channels dimension (for grayscale)\n",
        "        resized_image_array = resized_image_array.astype('float32') / 255.0  # Normalize pixel values\n",
        "\n",
        "        # Make a prediction\n",
        "        y_prob = loaded_model.predict(resized_image_array, batch_size=1, verbose=0)\n",
        "        y_pred = np.argmax(y_prob)\n",
        "\n",
        "        # Get the corresponding emotion label\n",
        "        emotion_label = mapper[y_pred]\n",
        "\n",
        "        # Append the result to the list\n",
        "        results.append([image_name, emotion_label])\n",
        "\n",
        "# Save the results to a CSV file\n",
        "csv_file_path = '/kaggle/working/results.csv'\n",
        "with open(csv_file_path, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Image', 'Emotion'])\n",
        "    writer.writerows(results)\n",
        "\n",
        "print(f'Results saved to {csv_file_path}')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-14T03:50:20.383882Z",
          "iopub.execute_input": "2024-06-14T03:50:20.384337Z"
        },
        "trusted": true,
        "id": "Voq4pYiEZk3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merging two csv files"
      ],
      "metadata": {
        "id": "8LcE2BdIZk3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the original CSV file with appropriate settings\n",
        "original_csv = '/kaggle/input/celeba-dataset/list_attr_celeba.csv'\n",
        "df_original = pd.read_csv(original_csv, index_col=0)\n",
        "\n",
        "# Load the second CSV file with new attributes\n",
        "new_csv = 'path_to_your_new_csv_file.csv'  # Replace with the actual path to your new CSV file\n",
        "df_new = pd.read_csv(new_csv)"
      ],
      "metadata": {
        "id": "TNW1BQKdZk3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the new columns to the original dataframe and initialize them with -1\n",
        "df_original['happy'] = -1\n",
        "df_original['sad'] = -1\n",
        "df_original['neutral'] = -1"
      ],
      "metadata": {
        "id": "YzePbqezZk3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the new columns based on the second CSV file\n",
        "for index, row in df_new.iterrows():\n",
        "    image_id = row['image_number']  # Assuming the column in new CSV is named 'image_number'\n",
        "    attribute = row['attribute']  # This should be one of 'happy', 'sad', 'neutral'\n",
        "\n",
        "    # Set the corresponding attribute column to 1\n",
        "    df_original.loc[image_id, attribute] = 1\n",
        "\n",
        "# Save the updated dataframe to a new CSV file\n",
        "df_original.to_csv('updated_celeba.csv')"
      ],
      "metadata": {
        "id": "eMjmgqaXZk3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "# Load the original and new CSV files\n",
        "df_original = pd.read_csv('/kaggle/input/celeba-dataset/list_attr_celeba.csv')\n",
        "df_new = pd.read_csv('/kaggle/input/emotionaldataset/results (1).csv')\n",
        "\n",
        "# Print column names for debugging purposes\n",
        "print(df_new.columns)\n",
        "\n",
        "# Assuming the column in the new CSV is named 'Image' for image_id and 'Emotion' for attribute\n",
        "for index, row in df_new.iterrows():\n",
        "    image_id = row['Image']  # Column name in the new CSV\n",
        "    attribute = row['Emotion']  # Column name in the new CSV ('happy', 'sad', 'neutral')\n",
        "\n",
        "    # Ensure the original DataFrame has the attribute columns\n",
        "    if attribute not in df_original.columns:\n",
        "        df_original[attribute] = 0\n",
        "\n",
        "    # Set the corresponding attribute column to 1\n",
        "    df_original.loc[df_original['image_id'] == image_id, attribute] = 1\n",
        "\n",
        "# Save the updated dataframe to a new CSV file\n",
        "df_original.to_csv('/kaggle/working/final_updated_celeba.csv', index=False)\n",
        "\n",
        "print(f'Updated CSV saved to /kaggle/working/updated_celeba.csv')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-14T10:13:13.086207Z",
          "iopub.execute_input": "2024-06-14T10:13:13.086528Z"
        },
        "trusted": true,
        "id": "SKhMFguMZk3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sort in Ascending Order**"
      ],
      "metadata": {
        "id": "lUMwhMEiZk3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Step 1: Read the CSV file\n",
        "file_path = '/kaggle/input/emotionaldataset/emotion.csv'  # Replace with your actual file path\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Step 2: Sort the DataFrame based on the 'image' column\n",
        "df_sorted = df.sort_values(by='Image')\n",
        "\n",
        "# Step 3: Save the sorted DataFrame to a new CSV file\n",
        "sorted_file_path = '/kaggle/working/sorted_file.csv'  # Replace with your desired output file path\n",
        "df_sorted.to_csv(sorted_file_path, index=False)\n",
        "\n",
        "print(f\"Sorted CSV file has been saved to {sorted_file_path}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-14T16:30:29.972124Z",
          "iopub.execute_input": "2024-06-14T16:30:29.972522Z",
          "iopub.status.idle": "2024-06-14T16:30:30.493047Z",
          "shell.execute_reply.started": "2024-06-14T16:30:29.972491Z",
          "shell.execute_reply": "2024-06-14T16:30:30.491966Z"
        },
        "trusted": true,
        "id": "Y6JV2ucuZk3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Read the CSV file\n",
        "file_path = '/kaggle/input/emotionaldataset/results (1).csv'  # Replace with your actual file path\n",
        "df2 = pd.read_csv(file_path)\n",
        "\n",
        "# Step 2: Count the number of images\n",
        "number_of_images = len(df['Image'])\n",
        "\n",
        "print(f\"Number of images in the CSV file: {number_of_images}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-14T16:35:51.142983Z",
          "iopub.execute_input": "2024-06-14T16:35:51.14337Z",
          "iopub.status.idle": "2024-06-14T16:35:51.344034Z",
          "shell.execute_reply.started": "2024-06-14T16:35:51.143341Z",
          "shell.execute_reply": "2024-06-14T16:35:51.343002Z"
        },
        "trusted": true,
        "id": "vra-lUdIZk3Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}