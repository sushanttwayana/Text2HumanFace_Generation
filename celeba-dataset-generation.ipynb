{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":8323379,"datasetId":4944262,"databundleVersionId":8454756},{"sourceType":"datasetVersion","sourceId":37705,"datasetId":29561,"databundleVersionId":39327},{"sourceType":"datasetVersion","sourceId":8695562,"datasetId":5204052,"databundleVersionId":8847993},{"sourceType":"datasetVersion","sourceId":8782421,"datasetId":5227713,"databundleVersionId":8938766}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sushanttwayana/celeba-dataset-generation?scriptVersionId=185397166\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import json\n\n# Load the JSON data from the file\nwith open('/kaggle/working/final_10000..json', 'r') as json_file:\n    data = json.load(json_file)\n\n# Define the desired text format\ntext = ''\n\n# Process each item in the list\nfor item in data:\n    text += f\"{item}\\n\"  # Assuming each item is a string representation\n\n# Write the text to a new file\nwith open('/kaggle/working/final_celeba_120000.txt', 'w') as text_file:\n    text_file.write(text)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-25T12:42:17.661276Z","iopub.execute_input":"2024-06-25T12:42:17.661636Z","iopub.status.idle":"2024-06-25T12:42:18.17734Z","shell.execute_reply.started":"2024-06-25T12:42:17.661609Z","shell.execute_reply":"2024-06-25T12:42:18.1762Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"import csv\nimport json\n\ndef csv_to_json(csv_file_path, json_file_path):\n    data = []\n    with open(csv_file_path, 'r') as csv_file:\n        csv_reader = csv.DictReader(csv_file)\n        for row in csv_reader:\n            data.append(row)\n    \n    with open(json_file_path, 'w') as json_file:\n        json.dump(data, json_file, indent=4)\n\n# Example usage\ncsv_to_json('/kaggle/working/final_sorted_10000_images.csv', '/kaggle/working/final_10000..json')","metadata":{"execution":{"iopub.status.busy":"2024-06-25T12:33:26.050092Z","iopub.execute_input":"2024-06-25T12:33:26.050476Z","iopub.status.idle":"2024-06-25T12:33:27.293922Z","shell.execute_reply.started":"2024-06-25T12:33:26.050446Z","shell.execute_reply":"2024-06-25T12:33:27.292789Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"import os\nimport csv\n\ndef generate_captions_from_attributes(attributes_file, output_file, exclude_attributes):\n    captions = []\n    \n    # Read the attributes from the file\n    with open(attributes_file, 'r') as file:\n        reader = csv.DictReader(file)\n        for row in reader:\n            image_id = row['image_id']\n            \n            # Convert attributes to textual description\n            description = []\n            gender = \"male\" if row['Male'] == '1' else \"female\"\n            description.append(f\"This person is {gender}\")\n            \n            pronoun = \"He\" if gender == \"male\" else \"She\"\n            possessive_pronoun = \"his\" if gender == \"male\" else \"her\"\n            \n            # Include attributes in the description\n            for attribute, value in row.items():\n                if attribute == 'image_id' or attribute == 'Male':\n                    continue\n                if exclude_attributes and attribute in exclude_attributes:\n                    continue\n                \n                if value == '1':\n                    if attribute == '5_o_Clock_Shadow':\n                        description.append(f\"{pronoun} has dense beard.\")\n                    elif attribute == 'Arched_Eyebrows':\n                        description.append(f\"{pronoun} has arched eyebrows.\")\n                    elif attribute == 'Attractive':\n                        description.append(f\"{pronoun} is attractive.\")\n                    elif attribute == 'Bags_Under_Eyes':\n                        description.append(f\"{pronoun} has bags under {possessive_pronoun} eyes.\")\n                    elif attribute == 'Bald':\n                        description.append(f\"{pronoun} is bald.\")\n                    elif attribute == 'Bangs':\n                        description.append(f\"{pronoun} has bangs.\")\n                    elif attribute == 'Big_Lips':\n                        description.append(f\"{pronoun} has big lips.\")\n                    elif attribute == 'Big_Nose':\n                        description.append(f\"{pronoun} has a big nose.\")\n                    elif attribute == 'Black_Hair':\n                        description.append(f\"{pronoun} has black hair.\")\n                    elif attribute == 'Blond_Hair':\n                        description.append(f\"{pronoun} has blonde hair.\")\n                    elif attribute == 'Brown_Hair':\n                        description.append(f\"{pronoun} has brown hair.\")\n                    elif attribute == 'Bushy_Eyebrows':\n                        description.append(f\"{pronoun} has bushy eyebrows.\")\n                    elif attribute == 'Chubby':\n                        description.append(f\"{pronoun} is chubby.\")\n                    elif attribute == 'Double_Chin':\n                        description.append(f\"{pronoun} has a double chin.\")\n                    elif attribute == 'Eyeglasses':\n                        description.append(f\"{pronoun} is wearing eyeglasses.\")\n                    elif attribute == 'Goatee':\n                        description.append(f\"{pronoun} has a goatee beard.\")\n                    elif attribute == 'Gray_Hair':\n                        description.append(f\"{pronoun} has gray hair.\")\n                    elif attribute == 'Heavy_Makeup':\n                        description.append(f\"{pronoun} is wearing heavy makeup.\")\n                    elif attribute == 'High_Cheekbones':\n                        description.append(f\"{pronoun} has high cheekbones.\")\n                    elif attribute == 'Mouth_Slightly_Open':\n                        description.append(f\"{pronoun} has {possessive_pronoun} mouth slightly open.\")\n                    elif attribute == 'Mustache':\n                        description.append(f\"{pronoun} has a mustache.\")\n                    elif attribute == 'Narrow_Eyes':\n                        description.append(f\"{pronoun} has narrow eyes.\")\n                    elif attribute == 'Oval_Face':\n                        description.append(f\"{pronoun} has an oval face.\")\n                    elif attribute == 'Pale_Skin':\n                        description.append(f\"{pronoun} has pale skin.\")\n                    elif attribute == 'Pointy_Nose':\n                        description.append(f\"{pronoun} has a pointy nose.\")   \n                    elif attribute == 'Receding_Hairline':\n                        description.append(f\"{pronoun} has a receding hairline.\")\n                    elif attribute == 'Rosy_Cheeks':\n                        description.append(f\"{pronoun} has rosy cheeks.\")\n                    elif attribute == 'Sideburns':\n                        description.append(f\"{pronoun} has sideburns.\")\n                    elif attribute == 'Smiling':\n                        description.append(f\"{pronoun} is smiling.\")\n                    elif attribute == 'Straight_Hair':\n                        description.append(f\"{pronoun} has straight hair.\")\n                    elif attribute == 'Wavy_Hair':\n                        description.append(f\"{pronoun} has wavy hair.\")\n                    elif attribute == 'Wearing_Earrings':\n                        description.append(f\"{pronoun} is wearing earrings.\")\n                    elif attribute == 'Wearing_Hat':\n                        description.append(f\"{pronoun} is wearing a hat.\")\n                    elif attribute == 'Wearing_Lipstick':\n                        description.append(f\"{pronoun} is wearing lipstick.\")\n                    elif attribute == 'Wearing_Necklace':\n                        description.append(f\"{pronoun} is wearing a necklace.\")\n                    elif attribute == 'Wearing_Necktie':\n                        description.append(f\"{pronoun} is wearing a necktie.\")\n                    elif attribute == 'Young':\n                        description.append(f\"{pronoun} is young.\")\n                    elif attribute == \"happy\":\n                        description.append(f\"{pronoun} is happy.\")\n                        description.append(f\"{pronoun} looks happy.\")\n                        description.append(f\"{pronoun} is joyful and delighted.\")\n                        description.append(f\"{pronoun} has a happy expression.\")\n                        description.append(f\"{pronoun} seems blissful.\")\n                        description.append(f\"{pronoun} is cheerful.\")\n                    elif attribute == \"sad\":\n                        description.append(f\"{pronoun} is sad.\")\n                        description.append(f\"{pronoun} looks sad.\")\n                        description.append(f\"{pronoun} looks unhappy and sad.\")\n                        description.append(f\"{pronoun} looks depressed.\")\n                        description.append(f\"{pronoun} is feeling down.\")\n                        description.append(f\"{pronoun} has a sad expression.\")\n                    elif attribute == \"neutral\":\n                        description.append(f\"{pronoun} is neutral.\")\n                        description.append(f\"{pronoun} stays calm and neutral.\")\n                        description.append(f\"{pronoun} stays open-minded and is fair-minded.\")\n                \n                elif value == '-1':\n                    if attribute == 'No_Beard':\n                        description.append(f\"{pronoun} has a beard.\")\n                    elif attribute == 'Young':\n                        description.append(f\"{pronoun} is old.\")\n                    elif attribute == 'Pale_Skin':\n                        description.append(f\"{pronoun} has brown skin.\")\n                    elif attribute == 'Chubby':\n                        description.append(f\"{pronoun} is slim.\")\n                    elif attribute == 'Bald':\n                        description.append(f\"{pronoun} has hair.\")\n                    elif attribute == 'Big_Lips':\n                        description.append(f\"{pronoun} has thin lips.\")\n                    elif attribute == 'Big_Nose':\n                        description.append(f\"{pronoun} has a small nose.\")\n                    elif attribute == 'Mustache':\n                        if row['Male'] == '1':\n                            description.append(f\"{pronoun} is clean-shaven and has no facial hairs.\")\n                        else :\n                            description.append(f\"{pronoun} has no facial hairs.\")\n                    elif attribute == 'Oval_Face':\n                        description.append(f\"{pronoun} has a round face.\")\n                    elif attribute == 'Straight_Hair':\n                        description.append(f\"{pronoun} has curly hair.\")\n                    elif attribute == 'Sideburns':\n                        description.append(f\"{pronoun} has bare cheeks. {pronoun} has no facial hair on the sides.\")\n                    elif attribute == 'Pointy_Nose':\n                        description.append(f\"{pronoun} has a rounded nose.\") \n                    elif attribute == 'High_Cheekbones':\n                        description.append(f\"{pronoun} has flat cheekbones.\")\n                    elif attribute == 'Heavy_Makeup':\n                        description.append(f\"{pronoun} is wearing no makeup. {pronoun} is wearing light makeup.\")\n                    elif attribute == 'Smiling':\n                        description.append(f\"{pronoun} is not smiling.\")\n                    elif attribute == 'Mouth_Slightly_Open':\n                        description.append(f\"{pronoun} has {possessive_pronoun} mouth closed.\")\n        \n            captions.append((image_id, ' '.join(description)))\n    \n    # Save captions to output file\n    if not os.path.exists(os.path.dirname(output_file)):\n        os.makedirs(os.path.dirname(output_file), exist_ok=True)\n        \n    with open(output_file, 'w') as file:\n        file.write(\"image,caption\\n\")  # Write the header line\n        for image_id, description in captions:\n            file.write(f\"{image_id},{description}\\n\")\n\n# Example usage:\nattributes_file = '/kaggle/working/sorted_10000_images.csv'\noutput_file = '/kaggle/working/descriptions/celeba_10000_captions.txt'\nexclude_attributes = ['Blurry']  # Example of attributes to exclude\ngenerate_captions_from_attributes(attributes_file, output_file, exclude_attributes)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-25T12:48:17.971427Z","iopub.execute_input":"2024-06-25T12:48:17.97184Z","iopub.status.idle":"2024-06-25T12:48:18.618684Z","shell.execute_reply.started":"2024-06-25T12:48:17.971807Z","shell.execute_reply":"2024-06-25T12:48:18.617542Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# from keras.utils.np_utils import to_categorical\n# import pandas as pd\n# import numpy as np\n# import random\n# import sys\n# import warnings \n# warnings.filterwarnings('ignore')\n\n# import matplotlib.pyplot as plt\n# %matplotlib inline\n\n# import brewer2mpl\n\n\n# def emotion_count(y_train, classes):\n#     \"\"\"\n#     The function re-classify picture with disgust label into angry label\n#     \"\"\"\n#     emo_classcount = {}\n#     print ('Disgust classified as Angry')\n#     y_train.loc[y_train == 1] = 0\n#     classes.remove('Disgust')\n#     for new_num, _class in enumerate(classes):\n#         y_train.loc[(y_train == emotion[_class])] = new_num\n#         class_count = sum(y_train == (new_num))\n#         emo_classcount[_class] = (new_num, class_count)\n#     return y_train.values, emo_classcount\n\n# def load_data(sample_split=0.3, usage='Training',classes=['Angry','Happy'], filepath='../input/fer20131.csv'):\n#     \"\"\"\n#     The function load provided CSV dataset and further reshape, rescale the data for feeding\n#     \"\"\"\n#     df = pd.read_csv(filepath)\n#     df = df[df.Usage == usage]\n#     frames = []\n#     classes.append('Disgust')\n#     for _class in classes:\n#         class_df = df[df['emotion'] == emotion[_class]]\n#         frames.append(class_df)\n#     data = pd.concat(frames, axis=0)\n#     rows = random.sample(list(data.index), int(len(data)*sample_split))\n#     data = data.loc[rows]\n#     x = list(data[\"pixels\"])\n#     X = []\n#     for i in range(len(x)):\n#         each_pixel = [int(num) for num in x[i].split()]\n#         X.append(each_pixel)\n#     ## reshape into 48*48*1 and rescale\n#     X = np.array(X)\n#     X = X.reshape(X.shape[0], 48, 48,1)\n#     X = X.astype(\"float32\")\n#     X /= 255\n    \n#     y_train, new_dict = emotion_count(data.emotion, classes)\n#     y_train = to_categorical(y_train)\n#     return X, y_train","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Emotional Dataset Generation","metadata":{}},{"cell_type":"code","source":"pip install tensorflow","metadata":{"execution":{"iopub.status.busy":"2024-06-14T03:47:21.175704Z","iopub.execute_input":"2024-06-14T03:47:21.176075Z","iopub.status.idle":"2024-06-14T03:47:37.859902Z","shell.execute_reply.started":"2024-06-14T03:47:21.176046Z","shell.execute_reply":"2024-06-14T03:47:37.858315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path ='/kaggle/input/your-dataset/your_model.h5'","metadata":{"execution":{"iopub.status.busy":"2024-06-14T03:48:07.75297Z","iopub.execute_input":"2024-06-14T03:48:07.760206Z","iopub.status.idle":"2024-06-14T03:48:07.770225Z","shell.execute_reply.started":"2024-06-14T03:48:07.76015Z","shell.execute_reply":"2024-06-14T03:48:07.766445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import h5py\nfrom tensorflow.keras.models import load_model\n\n# Load the model\nloaded_model = load_model('/kaggle/input/emotionaldataset/model.h5')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-14T03:48:10.783389Z","iopub.execute_input":"2024-06-14T03:48:10.784349Z","iopub.status.idle":"2024-06-14T03:48:25.698403Z","shell.execute_reply.started":"2024-06-14T03:48:10.784293Z","shell.execute_reply":"2024-06-14T03:48:25.697203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loaded_model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-06-14T03:48:38.388853Z","iopub.execute_input":"2024-06-14T03:48:38.389802Z","iopub.status.idle":"2024-06-14T03:48:38.452856Z","shell.execute_reply.started":"2024-06-14T03:48:38.389764Z","shell.execute_reply":"2024-06-14T03:48:38.451793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\n\n# Load the image\nimage_path = '/kaggle/input/celeba-dataset/img_align_celeba/img_align_celeba/000050.jpg'  # Replace with your image file path\nimage = Image.open(image_path)","metadata":{"execution":{"iopub.status.busy":"2024-06-13T17:10:01.624541Z","iopub.execute_input":"2024-06-13T17:10:01.624927Z","iopub.status.idle":"2024-06-13T17:10:01.639135Z","shell.execute_reply.started":"2024-06-13T17:10:01.624898Z","shell.execute_reply":"2024-06-13T17:10:01.637815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Resize the image to 48x48\nresized_image = image.resize((48, 48))\n\n# Convert the resized image to numpy array (optional)\nimport numpy as np\nresized_image_array = np.array(resized_image)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-13T17:10:04.154685Z","iopub.execute_input":"2024-06-13T17:10:04.155133Z","iopub.status.idle":"2024-06-13T17:10:04.163764Z","shell.execute_reply.started":"2024-06-13T17:10:04.155098Z","shell.execute_reply":"2024-06-13T17:10:04.161716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resized_image_gray = resized_image.convert('L')","metadata":{"execution":{"iopub.status.busy":"2024-06-13T17:10:06.789069Z","iopub.execute_input":"2024-06-13T17:10:06.789521Z","iopub.status.idle":"2024-06-13T17:10:06.795228Z","shell.execute_reply.started":"2024-06-13T17:10:06.789486Z","shell.execute_reply":"2024-06-13T17:10:06.79385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Display the grayscale image using matplotlib\nplt.imshow(resized_image_gray, cmap='gray')\nplt.axis('off')  # Hide axes for better visualization\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-13T17:10:09.525237Z","iopub.execute_input":"2024-06-13T17:10:09.525683Z","iopub.status.idle":"2024-06-13T17:10:09.620142Z","shell.execute_reply.started":"2024-06-13T17:10:09.52565Z","shell.execute_reply":"2024-06-13T17:10:09.618579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert the resized image to a format suitable for model input\nimport tensorflow as tf\nresized_image_array = np.expand_dims(resized_image_gray, axis=0)  # Add batch dimension\nresized_image_array = np.expand_dims(resized_image_array, axis=-1)  # Add channels dimension (for grayscale)\nresized_image_array = resized_image_array.astype('float32') / 255.0  # Normalize pixel values\n","metadata":{"execution":{"iopub.status.busy":"2024-06-13T17:10:13.492688Z","iopub.execute_input":"2024-06-13T17:10:13.493133Z","iopub.status.idle":"2024-06-13T17:10:13.500019Z","shell.execute_reply.started":"2024-06-13T17:10:13.493101Z","shell.execute_reply":"2024-06-13T17:10:13.498773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prediction and true labels\ny_prob = loaded_model.predict(resized_image_array, batch_size=1, verbose=0)\ny_pred = [np.argmax(prob) for prob in y_prob]\n\nprint(y_prob)\nprint(y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-06-13T17:10:16.408834Z","iopub.execute_input":"2024-06-13T17:10:16.409268Z","iopub.status.idle":"2024-06-13T17:10:16.508102Z","shell.execute_reply.started":"2024-06-13T17:10:16.40923Z","shell.execute_reply":"2024-06-13T17:10:16.506913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mapper = {\n    0: \"happy\",\n    1: \"sad\",\n    2: \"neutral\",\n}\n\nemo     = [\"happy\", 'sad', 'neutral']\n\n# Using list comprehension to retrieve elements\nresult = [emo[idx] for idx in y_pred]\n\nprint(result)","metadata":{"execution":{"iopub.status.busy":"2024-06-13T17:10:19.835881Z","iopub.execute_input":"2024-06-13T17:10:19.83627Z","iopub.status.idle":"2024-06-13T17:10:19.843745Z","shell.execute_reply.started":"2024-06-13T17:10:19.836242Z","shell.execute_reply":"2024-06-13T17:10:19.842571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport csv\nfrom PIL import Image\nimport numpy as np\nimport tensorflow as tf\n\n# Define the mapper and emotions\nmapper = {\n    0: \"happy\",\n    1: \"sad\",\n    2: \"neutral\",\n}\n\nemo = [\"happy\", \"sad\", \"neutral\"]\n\n# Load your pre-trained model\n# loaded_model = tf.keras.models.load_model('/kaggle/input/emotionaldataset/model.h5')\n\n# Define the directory containing tahe images\nimage_directory = '/kaggle/input/celeba-dataset/img_align_celeba/img_align_celeba'\n\n# Prepare a list to store results\nresults = []\n\n# Iterate over each image in the directory\nfor image_name in os.listdir(image_directory):\n    if image_name.endswith('.jpg'):  # Add other image formats if needed\n        image_path = os.path.join(image_directory, image_name)\n        \n        # Load and process the image\n        image = Image.open(image_path)\n        resized_image = image.resize((48, 48))\n        resized_image_gray = resized_image.convert('L')\n        resized_image_array = np.expand_dims(resized_image_gray, axis=0)  # Add batch dimension\n        resized_image_array = np.expand_dims(resized_image_array, axis=-1)  # Add channels dimension (for grayscale)\n        resized_image_array = resized_image_array.astype('float32') / 255.0  # Normalize pixel values\n\n        # Make a prediction\n        y_prob = loaded_model.predict(resized_image_array, batch_size=1, verbose=0)\n        y_pred = np.argmax(y_prob)\n\n        # Get the corresponding emotion label\n        emotion_label = mapper[y_pred]\n\n        # Append the result to the list\n        results.append([image_name, emotion_label])\n\n# Save the results to a CSV file\ncsv_file_path = '/kaggle/working/results.csv'\nwith open(csv_file_path, mode='w', newline='') as file:\n    writer = csv.writer(file)\n    writer.writerow(['Image', 'Emotion'])\n    writer.writerows(results)\n\nprint(f'Results saved to {csv_file_path}')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-14T03:50:20.383882Z","iopub.execute_input":"2024-06-14T03:50:20.384337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Merging two csv files ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Load the original CSV file with appropriate settings\noriginal_csv = '/kaggle/input/celeba-dataset/list_attr_celeba.csv'\ndf_original = pd.read_csv(original_csv, index_col=0) \n\n# Load the second CSV file with new attributes\nnew_csv = 'path_to_your_new_csv_file.csv'  # Replace with the actual path to your new CSV file\ndf_new = pd.read_csv(new_csv)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add the new columns to the original dataframe and initialize them with -1\ndf_original['happy'] = -1\ndf_original['sad'] = -1\ndf_original['neutral'] = -1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Update the new columns based on the second CSV file\nfor index, row in df_new.iterrows():\n    image_id = row['image_number']  # Assuming the column in new CSV is named 'image_number'\n    attribute = row['attribute']  # This should be one of 'happy', 'sad', 'neutral'\n    \n    # Set the corresponding attribute column to 1\n    df_original.loc[image_id, attribute] = 1\n\n# Save the updated dataframe to a new CSV file\ndf_original.to_csv('updated_celeba.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport csv\n\n# Load the original and new CSV files\ndf_original = pd.read_csv('/kaggle/input/celeba-dataset/list_attr_celeba.csv')\ndf_new = pd.read_csv('/kaggle/input/emotionaldataset/results (1).csv')\n\n# Print column names for debugging purposes\nprint(df_new.columns)\n\n# Assuming the column in the new CSV is named 'Image' for image_id and 'Emotion' for attribute\nfor index, row in df_new.iterrows():\n    image_id = row['Image']  # Column name in the new CSV\n    attribute = row['Emotion']  # Column name in the new CSV ('happy', 'sad', 'neutral')\n    \n    # Ensure the original DataFrame has the attribute columns\n    if attribute not in df_original.columns:\n        df_original[attribute] = 0\n\n    # Set the corresponding attribute column to 1\n    df_original.loc[df_original['image_id'] == image_id, attribute] = 1\n\n# Save the updated dataframe to a new CSV file\ndf_original.to_csv('/kaggle/working/final_updated_celeba.csv', index=False)\n\nprint(f'Updated CSV saved to /kaggle/working/updated_celeba.csv')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-14T10:13:13.086207Z","iopub.execute_input":"2024-06-14T10:13:13.086528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Sort in Ascending Order**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Step 1: Read the CSV file\nfile_path = '/kaggle/input/emotionaldataset/emotion.csv'  # Replace with your actual file path\ndf = pd.read_csv(file_path)\n\n# Step 2: Sort the DataFrame based on the 'image' column\ndf_sorted = df.sort_values(by='Image')\n\n# Step 3: Save the sorted DataFrame to a new CSV file\nsorted_file_path = '/kaggle/working/sorted_file.csv'  # Replace with your desired output file path\ndf_sorted.to_csv(sorted_file_path, index=False)\n\nprint(f\"Sorted CSV file has been saved to {sorted_file_path}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-25T12:14:45.728804Z","iopub.execute_input":"2024-06-25T12:14:45.729165Z","iopub.status.idle":"2024-06-25T12:14:46.771363Z","shell.execute_reply.started":"2024-06-25T12:14:45.729138Z","shell.execute_reply":"2024-06-25T12:14:46.770139Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Sorted CSV file has been saved to /kaggle/working/sorted_file.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# Step 1: Read the CSV file\nfile_path = '/kaggle/input/emotionaldataset/results (1).csv'  # Replace with your actual file path\ndf2 = pd.read_csv(file_path)\n\n# Step 2: Count the number of images\nnumber_of_images = len(df['Image'])\n\nprint(f\"Number of images in the CSV file: {number_of_images}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-25T12:14:51.865879Z","iopub.execute_input":"2024-06-25T12:14:51.866261Z","iopub.status.idle":"2024-06-25T12:14:52.084291Z","shell.execute_reply.started":"2024-06-25T12:14:51.866233Z","shell.execute_reply":"2024-06-25T12:14:52.083114Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Number of images in the CSV file: 120000\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Generating 10000","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport os\nimport shutil\n\n# Paths\ncsv_path = '/kaggle/input/final-celeba-12000/final_sorted_csv_120000.csv'\nimages_path = '/kaggle/input/final-celeba-12000/_output_/final_celeba_img_120000'\noutput_csv_path = '/kaggle/working/sorted_10000_images.csv'\noutput_images_path = '/kaggle/working/selected_images/'\n\n# Load the CSV file\ndf = pd.read_csv(csv_path)\n\n# Randomly sample 10,000 rows\nsampled_df = df.sample(n=10000, random_state=42)\n\n# Save the sampled DataFrame to a new CSV file\nsampled_df.to_csv(output_csv_path, index=False)\n\n# Count the number of images in the sampled DataFrame\nnumber_of_images = len(sampled_df)\nprint(f\"Number of images in the sampled CSV file: {number_of_images}\")\n\n# Create the output directory for images if it doesn't exist\nos.makedirs(output_images_path, exist_ok=True)\n\n# Copy the selected images to the new directory\nfor image_id in sampled_df['image_id']:\n    src_image_path = os.path.join(images_path, image_id)\n    dst_image_path = os.path.join(output_images_path, image_id)\n    shutil.copy(src_image_path, dst_image_path)\n\nprint(f\"Selected 10,000 images and saved to {output_images_path} and the CSV to {output_csv_path}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-25T15:37:47.637605Z","iopub.execute_input":"2024-06-25T15:37:47.637991Z","iopub.status.idle":"2024-06-25T15:38:28.393599Z","shell.execute_reply.started":"2024-06-25T15:37:47.63796Z","shell.execute_reply":"2024-06-25T15:38:28.392419Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Number of images in the sampled CSV file: 10000\nSelected 10,000 images and saved to /kaggle/working/selected_images/ and the CSV to /kaggle/working/sorted_10000_images.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\n# Step 1: Read the CSV file\nfile_path = '/kaggle/working/sorted_10000_images.csv'  \ndf = pd.read_csv(file_path)\n\n# Step 2: Sort the DataFrame based on the 'image' column\ndf_sorted = df.sort_values(by='image_id')\n\n# Step 3: Save the sorted DataFrame to a new CSV file\nsorted_file_path = '/kaggle/working/final_sorted_10000_images.csv'  # Replace with your desired output file path\ndf_sorted.to_csv(sorted_file_path, index=False)\n\nprint(f\"Sorted CSV file has been saved to {sorted_file_path}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-25T12:31:39.366893Z","iopub.execute_input":"2024-06-25T12:31:39.367282Z","iopub.status.idle":"2024-06-25T12:31:39.632991Z","shell.execute_reply.started":"2024-06-25T12:31:39.367252Z","shell.execute_reply":"2024-06-25T12:31:39.631922Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Sorted CSV file has been saved to /kaggle/working/final_sorted_10000_images.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"file_path = '/kaggle/working/sorted_10000_images.csv'  # Replace with your actual file path\ndf2 = pd.read_csv(file_path)\n\n# Step 2: Count the number of images\nnumber_of_images = len(df['image_id'])\n\nprint(f\"Number of images in the CSV file: {number_of_images}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-25T12:32:28.812955Z","iopub.execute_input":"2024-06-25T12:32:28.813402Z","iopub.status.idle":"2024-06-25T12:32:28.869234Z","shell.execute_reply.started":"2024-06-25T12:32:28.813363Z","shell.execute_reply":"2024-06-25T12:32:28.868026Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Number of images in the CSV file: 10000\n","output_type":"stream"}]}]}